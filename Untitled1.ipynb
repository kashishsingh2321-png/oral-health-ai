{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kashishsingh2321-png/oral-health-ai/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0BRLQMhJEbVJ",
        "outputId": "7cebc3fa-1106-4f0d-d7b7-ad2e1e651643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5c053f5be72a1a04fd.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5c053f5be72a1a04fd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://bef508367509e01196.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bef508367509e01196.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3ae2fa6547c58734be.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3ae2fa6547c58734be.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MobileNetV2 (for embeddings)... (this may take a few seconds)\n",
            "Prototypes built for classes: ['pizza']\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://79ac99f35325cc9339.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://79ac99f35325cc9339.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount Drive (optional)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# install libs\n",
        "!pip install -q gradio pandas requests\n",
        "\n",
        "import requests, json, time\n",
        "\n",
        "API_KEY = \"YOUR_USDA_API_KEY\"   # get from FoodData Central site\n",
        "SEARCH_URL = \"https://api.nal.usda.gov/fdc/v1/foods/search\"\n",
        "\n",
        "def lookup_nutrition(food_name):\n",
        "    params = {\"api_key\": API_KEY, \"query\": food_name, \"pageSize\": 1}\n",
        "    r = requests.get(SEARCH_URL, params=params)\n",
        "    data = r.json()\n",
        "    # simple parse: get sugar & calcium if available\n",
        "    sugar_g = None\n",
        "    calcium_mg = None\n",
        "    try:\n",
        "        nutrients = data['foods'][0]['foodNutrients']\n",
        "        for n in nutrients:\n",
        "            name = n.get('nutrientName','').lower()\n",
        "            if 'sugar' in name: sugar_g = n.get('value')\n",
        "            if 'calcium' in name: calcium_mg = n.get('value')\n",
        "    except Exception:\n",
        "        pass\n",
        "    time.sleep(0.3)  # rate-limit politely\n",
        "    return {\"sugar_g\": sugar_g or 0, \"calcium_mg\": calcium_mg or 0}\n",
        "\n",
        "def compute_risk_from_items(items, meals_per_day=3):\n",
        "    total_sugar = 0\n",
        "    total_calcium = 0\n",
        "    n = max(1, len(items))\n",
        "    # fallback heuristics\n",
        "    acidic_keywords = {'cola','lemon','orange','citrus','vinegar','pickles','sports drink'}\n",
        "    sticky_keywords = {'chocolate','toffee','caramel','dates','jaggery','chewing gum'}\n",
        "    refined_keywords = {'white bread','bread','pizza','biscuits','chips','maida','maggi'}\n",
        "\n",
        "    acid_flag = False\n",
        "    sticky_count = 0\n",
        "    refined_count = 0\n",
        "\n",
        "    for it in items:\n",
        "        it = it.strip().lower()\n",
        "        nut = lookup_nutrition(it)  # use the USDA function above or local CSV fallback\n",
        "        total_sugar += float(nut.get('sugar_g',0))\n",
        "        total_calcium += float(nut.get('calcium_mg',0))\n",
        "\n",
        "        if any(k in it for k in acidic_keywords): acid_flag = True\n",
        "        if any(k in it for k in sticky_keywords): sticky_count += 1\n",
        "        if any(k in it for k in refined_keywords): refined_count += 1\n",
        "\n",
        "    sugar_score = min(1.0, total_sugar / 50.0)         # 50g sugar ~ very high\n",
        "    refined_frac = refined_count / n\n",
        "    sticky_frac = sticky_count / n\n",
        "    freq_factor = min(1.0, meals_per_day / 6.0)\n",
        "    calcium_factor = min(1.0, total_calcium / (n*200)) # more calcium protective\n",
        "\n",
        "    cavity = min(1.0, 0.6*sugar_score + 0.15*refined_frac + 0.1*sticky_frac + 0.05*freq_factor)\n",
        "    enamel = min(1.0, 0.5*(1 if acid_flag else 0) + 0.3*sugar_score + 0.2*freq_factor - 0.2*calcium_factor)\n",
        "    gum = min(1.0, 0.6*(1 - calcium_factor) + 0.4*refined_frac)\n",
        "\n",
        "    return {\"cavity\":cavity, \"enamel\":enamel, \"gum\":gum}\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def predict_from_text(food_text, meals_per_day=3):\n",
        "    items = [f.strip() for f in food_text.split(',') if f.strip()]\n",
        "    scores = compute_risk_from_items(items, meals_per_day)\n",
        "    out = (f\"Cavity Risk: {int(scores['cavity']*100)}%\\n\"\n",
        "           f\"Enamel Erosion Risk: {int(scores['enamel']*100)}%\\n\"\n",
        "           f\"Gum-Health Risk: {int(scores['gum']*100)}%\")\n",
        "    suggestions = []\n",
        "    if scores['cavity']>0.4: suggestions.append(\"Limit sugary drinks; rinse with water after sweets.\")\n",
        "    if scores['enamel']>0.3: suggestions.append(\"Avoid sipping acidic drinks slowly; use a straw.\")\n",
        "    if not suggestions: suggestions.append(\"Good — include dairy or crunchy veggies after a meal.\")\n",
        "    return out, \"\\n\".join(suggestions)\n",
        "\n",
        "demo = gr.Interface(fn=predict_from_text,\n",
        "                    inputs=[gr.Textbox(lines=2,placeholder=\"e.g. cola, cheese, bread\"),\n",
        "                            gr.Slider(1,8,value=3,label=\"Meals/snacks per day\")],\n",
        "                    outputs=[gr.Textbox(), gr.Textbox()],\n",
        "                    title=\"Oral-Health Dietary Advisor (Prototype)\")\n",
        "demo.launch()\n",
        "\n",
        "# ==============================\n",
        "#  STEP 1: Install dependencies\n",
        "# ==============================\n",
        "!pip install -q gradio pandas requests\n",
        "\n",
        "# ==============================\n",
        "#  STEP 2: Nutrition lookup helper\n",
        "# (using USDA FoodData API — OR fallback dummy values if no API key)\n",
        "# ==============================\n",
        "import requests, time\n",
        "\n",
        "API_KEY = \"\"   # <-- (Optional) Put your USDA API Key here (https://fdc.nal.usda.gov/)\n",
        "SEARCH_URL = \"https://api.nal.usda.gov/fdc/v1/foods/search\"\n",
        "\n",
        "def lookup_nutrition(food_name):\n",
        "    if not API_KEY:  # fallback dummy values if no key\n",
        "        # Just heuristic placeholder values\n",
        "        return {\"sugar_g\": 5 if \"cola\" in food_name else 1,\n",
        "                \"calcium_mg\": 100 if \"milk\" in food_name else 20}\n",
        "\n",
        "    params = {\"api_key\": API_KEY, \"query\": food_name, \"pageSize\": 1}\n",
        "    r = requests.get(SEARCH_URL, params=params)\n",
        "    data = r.json()\n",
        "    sugar_g, calcium_mg = 0, 0\n",
        "    try:\n",
        "        nutrients = data['foods'][0]['foodNutrients']\n",
        "        for n in nutrients:\n",
        "            name = n.get('nutrientName','').lower()\n",
        "            if 'sugar' in name: sugar_g = n.get('value',0)\n",
        "            if 'calcium' in name: calcium_mg = n.get('value',0)\n",
        "    except Exception:\n",
        "        pass\n",
        "    time.sleep(0.3)  # avoid rate limit\n",
        "    return {\"sugar_g\": sugar_g, \"calcium_mg\": calcium_mg}\n",
        "\n",
        "\n",
        "# ==============================\n",
        "#  STEP 3: Risk calculator\n",
        "# ==============================\n",
        "def compute_risk_from_items(items, meals_per_day=3):\n",
        "    total_sugar = 0\n",
        "    total_calcium = 0\n",
        "    n = max(1, len(items))\n",
        "\n",
        "    acidic_keywords = {'cola','lemon','orange','citrus','vinegar','pickles','sports drink'}\n",
        "    sticky_keywords = {'chocolate','toffee','caramel','dates','jaggery','chewing gum'}\n",
        "    refined_keywords = {'white bread','bread','pizza','biscuits','chips','maida','maggi'}\n",
        "\n",
        "    acid_flag = False\n",
        "    sticky_count = 0\n",
        "    refined_count = 0\n",
        "\n",
        "    for it in items:\n",
        "        it = it.strip().lower()\n",
        "        nut = lookup_nutrition(it)\n",
        "        total_sugar += float(nut.get('sugar_g',0))\n",
        "        total_calcium += float(nut.get('calcium_mg',0))\n",
        "\n",
        "        if any(k in it for k in acidic_keywords): acid_flag = True\n",
        "        if any(k in it for k in sticky_keywords): sticky_count += 1\n",
        "        if any(k in it for k in refined_keywords): refined_count += 1\n",
        "\n",
        "    sugar_score = min(1.0, total_sugar / 50.0)\n",
        "    refined_frac = refined_count / n\n",
        "    sticky_frac = sticky_count / n\n",
        "    freq_factor = min(1.0, meals_per_day / 6.0)\n",
        "    calcium_factor = min(1.0, total_calcium / (n*200))\n",
        "\n",
        "    cavity = min(1.0, 0.6*sugar_score + 0.15*refined_frac + 0.1*sticky_frac + 0.05*freq_factor)\n",
        "    enamel = min(1.0, 0.5*(1 if acid_flag else 0) + 0.3*sugar_score + 0.2*freq_factor - 0.15*calcium_factor)\n",
        "    gum = min(1.0, 0.6*(1 - calcium_factor) + 0.4*refined_frac)\n",
        "\n",
        "    return {\"cavity\":cavity, \"enamel\":enamel, \"gum\":gum}\n",
        "\n",
        "\n",
        "# ==============================\n",
        "#  STEP 4: Gradio Demo\n",
        "# ==============================\n",
        "import gradio as gr\n",
        "\n",
        "def predict_from_text(food_text, meals_per_day=3):\n",
        "    items = [f.strip() for f in food_text.split(',') if f.strip()]\n",
        "    scores = compute_risk_from_items(items, meals_per_day)\n",
        "    out = (f\"Cavity Risk: {int(scores['cavity']*100)}%\\n\"\n",
        "           f\"Enamel Erosion Risk: {int(scores['enamel']*100)}%\\n\"\n",
        "           f\"Gum-Health Risk: {int(scores['gum']*100)}%\")\n",
        "    suggestions = []\n",
        "    if scores['cavity']>0.4: suggestions.append(\"Limit sugary drinks; rinse with water after sweets.\")\n",
        "    if scores['enamel']>0.3: suggestions.append(\"Avoid sipping acidic drinks slowly; use a straw.\")\n",
        "    if not suggestions: suggestions.append(\"Good — include dairy or crunchy veggies after a meal.\")\n",
        "    return out, \"\\n\".join(suggestions)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_from_text,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=2,placeholder=\"e.g. cola, cheese, bread\"),\n",
        "        gr.Slider(1,8,value=3,label=\"Meals/snacks per day\")\n",
        "    ],\n",
        "    outputs=[gr.Textbox(label=\"Risk Scores\"), gr.Textbox(label=\"Suggestions\")],\n",
        "    title=\"🦷 Oral-Health Dietary Advisor (Prototype)\",\n",
        "    description=\"Made by Kashish\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)  # share=True gives you a public link\n",
        "\n",
        "# ==============================\n",
        "#  STEP 1: Install dependencies\n",
        "# ==============================\n",
        "!pip install -q gradio pandas requests\n",
        "\n",
        "# ==============================\n",
        "#  STEP 2: Nutrition lookup helper\n",
        "# (using USDA FoodData API — OR fallback dummy values if no API key)\n",
        "# ==============================\n",
        "import requests, time\n",
        "\n",
        "API_KEY = \"\"   # <-- (Optional) Put your USDA API Key here (https://fdc.nal.usda.gov/)\n",
        "SEARCH_URL = \"https://api.nal.usda.gov/fdc/v1/foods/search\"\n",
        "\n",
        "def lookup_nutrition(food_name):\n",
        "    if not API_KEY:  # fallback dummy values if no key\n",
        "        # Just heuristic placeholder values\n",
        "        return {\"sugar_g\": 5 if \"cola\" in food_name else 1,\n",
        "                \"calcium_mg\": 100 if \"milk\" in food_name else 20}\n",
        "\n",
        "    params = {\"api_key\": API_KEY, \"query\": food_name, \"pageSize\": 1}\n",
        "    r = requests.get(SEARCH_URL, params=params)\n",
        "    data = r.json()\n",
        "    sugar_g, calcium_mg = 0, 0\n",
        "    try:\n",
        "        nutrients = data['foods'][0]['foodNutrients']\n",
        "        for n in nutrients:\n",
        "            name = n.get('nutrientName','').lower()\n",
        "            if 'sugar' in name: sugar_g = n.get('value',0)\n",
        "            if 'calcium' in name: calcium_mg = n.get('value',0)\n",
        "    except Exception:\n",
        "        pass\n",
        "    time.sleep(0.3)  # avoid rate limit\n",
        "    return {\"sugar_g\": sugar_g, \"calcium_mg\": calcium_mg}\n",
        "\n",
        "\n",
        "# ==============================\n",
        "#  STEP 3: Risk calculator\n",
        "# ==============================\n",
        "def compute_risk_from_items(items, meals_per_day=3):\n",
        "    total_sugar = 0\n",
        "    total_calcium = 0\n",
        "    n = max(1, len(items))\n",
        "\n",
        "    acidic_keywords = {'cola','lemon','orange','citrus','vinegar','pickles','sports drink'}\n",
        "    sticky_keywords = {'chocolate','toffee','caramel','dates','jaggery','chewing gum'}\n",
        "    refined_keywords = {'white bread','bread','pizza','biscuits','chips','maida','maggi'}\n",
        "\n",
        "    acid_flag = False\n",
        "    sticky_count = 0\n",
        "    refined_count = 0\n",
        "\n",
        "    for it in items:\n",
        "        it = it.strip().lower()\n",
        "        nut = lookup_nutrition(it)\n",
        "        total_sugar += float(nut.get('sugar_g',0))\n",
        "        total_calcium += float(nut.get('calcium_mg',0))\n",
        "\n",
        "        if any(k in it for k in acidic_keywords): acid_flag = True\n",
        "        if any(k in it for k in sticky_keywords): sticky_count += 1\n",
        "        if any(k in it for k in refined_keywords): refined_count += 1\n",
        "\n",
        "    sugar_score = min(1.0, total_sugar / 50.0)\n",
        "    refined_frac = refined_count / n\n",
        "    sticky_frac = sticky_count / n\n",
        "    freq_factor = min(1.0, meals_per_day / 6.0)\n",
        "    calcium_factor = min(1.0, total_calcium / (n*200))\n",
        "\n",
        "    cavity = min(1.0, 0.6*sugar_score + 0.15*refined_frac + 0.1*sticky_frac + 0.05*freq_factor)\n",
        "    enamel = min(1.0, 0.5*(1 if acid_flag else 0) + 0.3*sugar_score + 0.2*freq_factor - 0.15*calcium_factor)\n",
        "    gum = min(1.0, 0.6*(1 - calcium_factor) + 0.4*refined_frac)\n",
        "\n",
        "    return {\"cavity\":cavity, \"enamel\":enamel, \"gum\":gum}\n",
        "\n",
        "\n",
        "# ==============================\n",
        "#  STEP 4: Gradio Demo\n",
        "# ==============================\n",
        "import gradio as gr\n",
        "\n",
        "def predict_from_text(food_text, meals_per_day=3):\n",
        "    items = [f.strip() for f in food_text.split(',') if f.strip()]\n",
        "    scores = compute_risk_from_items(items, meals_per_day)\n",
        "    out = (f\"Cavity Risk: {int(scores['cavity']*100)}%\\n\"\n",
        "           f\"Enamel Erosion Risk: {int(scores['enamel']*100)}%\\n\"\n",
        "           f\"Gum-Health Risk: {int(scores['gum']*100)}%\")\n",
        "    suggestions = []\n",
        "    if scores['cavity']>0.4: suggestions.append(\"Limit sugary drinks; rinse with water after sweets.\")\n",
        "    if scores['enamel']>0.3: suggestions.append(\"Avoid sipping acidic drinks slowly; use a straw.\")\n",
        "    if not suggestions: suggestions.append(\"Good — include dairy or crunchy veggies after a meal.\")\n",
        "    return out, \"\\n\".join(suggestions)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_from_text,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=2,placeholder=\"e.g. cola, cheese, bread\"),\n",
        "        gr.Slider(1,8,value=3,label=\"Meals/snacks per day\")\n",
        "    ],\n",
        "    outputs=[gr.Textbox(label=\"Risk Scores\"), gr.Textbox(label=\"Suggestions\")],\n",
        "    title=\"🦷 Oral-Health Dietary Advisor (Prototype)\",\n",
        "    description=\"Made by Kashish\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)  # share=True gives you a public link\n",
        "\n",
        "# =========================\n",
        "# Oral-Health Dietary Advisor (Upgraded)\n",
        "# Made by Kashish using Python 🐍\n",
        "# Copy-paste this into Google Colab and run.\n",
        "# =========================\n",
        "\n",
        "# Install required packages (runs quickly)\n",
        "!pip install -q gradio tensorflow pandas pillow\n",
        "\n",
        "# -------------------------\n",
        "# Imports\n",
        "# -------------------------\n",
        "import os, glob, time, csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras import layers\n",
        "import gradio as gr\n",
        "\n",
        "# -------------------------\n",
        "# 1) Prepare tiny reference images for few-shot recognition\n",
        "#    (You can replace/add your own images in /content/reference/<class>/)\n",
        "# -------------------------\n",
        "ref_dir = \"/content/reference\"\n",
        "os.makedirs(ref_dir, exist_ok=True)\n",
        "\n",
        "# classes we support by default\n",
        "DEFAULT_CLASSES = [\"pizza\", \"cola\", \"salad\", \"ice_cream\", \"bread\"]\n",
        "for cls in DEFAULT_CLASSES:\n",
        "    os.makedirs(os.path.join(ref_dir, cls), exist_ok=True)\n",
        "\n",
        "# download a couple of quick public images per class (small, Wikimedia)\n",
        "# these are only for demo; replace with your own photos for best performance\n",
        "examples = {\n",
        "    \"pizza\": [\n",
        "        \"https://upload.wikimedia.org/wikipedia/commons/6/65/Pizza_on_stone.jpg\",\n",
        "        \"https://upload.wikimedia.org/wikipedia/commons/d/d3/Supreme_pizza.jpg\"\n",
        "    ],\n",
        "    \"cola\": [\n",
        "        \"https://upload.wikimedia.org/wikipedia/commons/1/14/Coca-Cola_Glass_Bottle.jpg\",\n",
        "        \"https://upload.wikimedia.org/wikipedia/commons/1/18/Coca-Cola_bottle_cap.jpg\"\n",
        "    ],\n",
        "    \"salad\": [\n",
        "        \"https://upload.wikimedia.org/wikipedia/commons/9/94/Greek_salad.jpg\",\n",
        "        \"https://upload.wikimedia.org/wikipedia/commons/4/47/Salad_platter.jpg\"\n",
        "    ],\n",
        "    \"ice_cream\": [\n",
        "        \"https://upload.wikimedia.org/wikipedia/commons/2/2c/Ice_Cream_Double_Scoop.jpg\",\n",
        "        \"https://upload.wikimedia.org/wikipedia/commons/9/9f/Strawberry_ice_cream_cone-1.jpg\"\n",
        "    ],\n",
        "    \"bread\": [\n",
        "        \"https://upload.wikimedia.org/wikipedia/commons/0/0b/Loaf_of_bread.jpg\",\n",
        "        \"https://upload.wikimedia.org/wikipedia/commons/3/3a/White_bread.jpg\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Download only if not already present\n",
        "for cls, urls in examples.items():\n",
        "    for i, url in enumerate(urls, start=1):\n",
        "        outp = os.path.join(ref_dir, cls, f\"{i}.jpg\")\n",
        "        if not os.path.exists(outp):\n",
        "            try:\n",
        "                !wget -q -O \"{outp}\" \"{url}\"\n",
        "            except Exception:\n",
        "                pass  # network hiccup won't break the rest\n",
        "\n",
        "# -------------------------\n",
        "# 2) Build embedding model (MobileNetV2 -> GlobalAveragePooling)\n",
        "#    We will compute embeddings for reference images and average them into prototypes.\n",
        "# -------------------------\n",
        "print(\"Loading MobileNetV2 (for embeddings)... (this may take a few seconds)\")\n",
        "base = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
        "embed_model = tf.keras.Sequential([base, layers.GlobalAveragePooling2D()])\n",
        "\n",
        "# helper: image path -> normalized embedding\n",
        "def embedding_from_path(p):\n",
        "    img = Image.open(p).convert(\"RGB\").resize((224,224))\n",
        "    arr = np.array(img).astype(np.float32)\n",
        "    arr = np.expand_dims(arr, 0)\n",
        "    arr = preprocess_input(arr)\n",
        "    emb = embed_model.predict(arr, verbose=0)[0]\n",
        "    emb = emb / (np.linalg.norm(emb) + 1e-10)\n",
        "    return emb\n",
        "\n",
        "# build prototypes\n",
        "def build_prototypes(reference_folder=ref_dir):\n",
        "    prototypes = {}\n",
        "    class_files = {}\n",
        "    for cls in sorted(os.listdir(reference_folder)):\n",
        "        cls_path = os.path.join(reference_folder, cls)\n",
        "        if not os.path.isdir(cls_path):\n",
        "            continue\n",
        "        files = glob.glob(os.path.join(cls_path, \"*\"))\n",
        "        if len(files) == 0:\n",
        "            continue\n",
        "        embs = []\n",
        "        for f in files:\n",
        "            try:\n",
        "                embs.append(embedding_from_path(f))\n",
        "            except Exception:\n",
        "                continue\n",
        "        if len(embs) > 0:\n",
        "            proto = np.mean(np.stack(embs, axis=0), axis=0)\n",
        "            proto = proto / (np.linalg.norm(proto) + 1e-10)\n",
        "            prototypes[cls] = proto\n",
        "            class_files[cls] = files\n",
        "    return prototypes, class_files\n",
        "\n",
        "prototypes, class_files = build_prototypes()\n",
        "print(\"Prototypes built for classes:\", list(prototypes.keys()))\n",
        "\n",
        "# -------------------------\n",
        "# 3) Image classification by cosine similarity (few-shot)\n",
        "# -------------------------\n",
        "def classify_image_by_prototype(pil_image):\n",
        "    # pil_image: PIL.Image or numpy array; convert to array\n",
        "    if isinstance(pil_image, np.ndarray):\n",
        "        img = Image.fromarray(pil_image).convert(\"RGB\")\n",
        "    else:\n",
        "        img = pil_image.convert(\"RGB\")\n",
        "    img = img.resize((224,224))\n",
        "    arr = np.array(img).astype(np.float32)\n",
        "    arr = np.expand_dims(arr,0)\n",
        "    arr = preprocess_input(arr)\n",
        "    emb = embed_model.predict(arr, verbose=0)[0]\n",
        "    emb = emb / (np.linalg.norm(emb)+1e-10)\n",
        "    # compute cosine similarities\n",
        "    sims = {cls: float(np.dot(proto, emb)) for cls, proto in prototypes.items()}\n",
        "    if len(sims)==0:\n",
        "        return None, {}\n",
        "    best = max(sims, key=sims.get)\n",
        "    # return label, scores dict (sorted)\n",
        "    sorted_scores = dict(sorted(sims.items(), key=lambda kv: kv[1], reverse=True))\n",
        "    return best, sorted_scores\n",
        "\n",
        "# -------------------------\n",
        "# 4) Nutrition lookup stub (expand later or connect USDA API)\n",
        "# -------------------------\n",
        "# small built-in nutrition mapping (sugar_g per serving, calcium_mg)\n",
        "NUTR_DB = {\n",
        "    \"cola\": {\"sugar_g\": 35, \"calcium_mg\": 2, \"is_acidic\": True},\n",
        "    \"pizza\": {\"sugar_g\": 6, \"calcium_mg\": 40, \"is_acidic\": False},\n",
        "    \"salad\": {\"sugar_g\": 3, \"calcium_mg\": 30, \"is_acidic\": False},\n",
        "    \"ice_cream\": {\"sugar_g\": 20, \"calcium_mg\": 80, \"is_acidic\": False},\n",
        "    \"bread\": {\"sugar_g\": 3, \"calcium_mg\": 20, \"is_acidic\": False}\n",
        "}\n",
        "def lookup_nutrition_stub(name):\n",
        "    name = name.lower()\n",
        "    # direct match or substring match fallback\n",
        "    if name in NUTR_DB:\n",
        "        return NUTR_DB[name]\n",
        "    for k in NUTR_DB:\n",
        "        if k in name:\n",
        "            return NUTR_DB[k]\n",
        "    # conservative default\n",
        "    return {\"sugar_g\": 5, \"calcium_mg\": 10, \"is_acidic\": False}\n",
        "\n",
        "# -------------------------\n",
        "# 5) Risk calculator (improved with lifestyle multipliers & explainability)\n",
        "# -------------------------\n",
        "def compute_risk_and_explain(detected_items, meals_per_day=3, brushes_per_day=1, smokes=False, sugary_drinks_per_day=0):\n",
        "    \"\"\"\n",
        "    detected_items: list of food names (strings)\n",
        "    brushes_per_day: 0,1,2+\n",
        "    smokes: boolean\n",
        "    sugary_drinks_per_day: int\n",
        "    returns dict with risks and explanation\n",
        "    \"\"\"\n",
        "    # aggregate nutrition\n",
        "    total_sugar = 0.0\n",
        "    total_calcium = 0.0\n",
        "    acid_present = False\n",
        "    sticky_count = 0\n",
        "    refined_count = 0\n",
        "    details = []\n",
        "    for it in detected_items:\n",
        "        nut = lookup_nutrition_stub(it)\n",
        "        sugar = float(nut.get(\"sugar_g\", 0))\n",
        "        calcium = float(nut.get(\"calcium_mg\", 0))\n",
        "        is_acidic = bool(nut.get(\"is_acidic\", False))\n",
        "        total_sugar += sugar\n",
        "        total_calcium += calcium\n",
        "        acid_present = acid_present or is_acidic\n",
        "        # heuristic sticky/refined detection\n",
        "        if any(k in it.lower() for k in [\"chocolate\",\"toffee\",\"caramel\",\"caramel\",\"ice_cream\",\"dessert\"]):\n",
        "            sticky_count += 1\n",
        "        if any(k in it.lower() for k in [\"bread\",\"pizza\",\"biscuits\",\"chips\",\"maggi\"]):\n",
        "            refined_count += 1\n",
        "        details.append({\"item\":it, \"sugar_g\":sugar, \"calcium_mg\":calcium, \"acidic\":is_acidic})\n",
        "\n",
        "    n = max(1, len(detected_items))\n",
        "    sugar_score = min(1.0, total_sugar / 50.0)\n",
        "    refined_frac = refined_count / n\n",
        "    sticky_frac = sticky_count / n\n",
        "    freq_factor = min(1.0, meals_per_day / 6.0)\n",
        "    calcium_factor = min(1.0, total_calcium / (n*200.0))\n",
        "\n",
        "    # base risks\n",
        "    cavity = min(1.0, 0.6*sugar_score + 0.15*refined_frac + 0.1*sticky_frac + 0.05*freq_factor)\n",
        "    enamel = min(1.0, 0.5*(1 if acid_present else 0) + 0.3*sugar_score + 0.2*freq_factor - 0.15*calcium_factor)\n",
        "    gum = min(1.0, 0.6*(1 - calcium_factor) + 0.4*refined_frac)\n",
        "\n",
        "    # lifestyle modifiers\n",
        "    # brushing reduces cavity risk (two brushes per day gives stronger protection)\n",
        "    if brushes_per_day >= 2:\n",
        "        cavity *= 0.7\n",
        "        gum *= 0.9\n",
        "    elif brushes_per_day == 1:\n",
        "        cavity *= 0.9\n",
        "\n",
        "    # smoking increases gum risk significantly\n",
        "    if smokes:\n",
        "        gum = min(1.0, gum * 1.4)\n",
        "\n",
        "    # sugary drinks frequency increases cavity & enamel risks\n",
        "    if sugary_drinks_per_day >= 2:\n",
        "        cavity = min(1.0, cavity * 1.2)\n",
        "        enamel = min(1.0, enamel * 1.15)\n",
        "    elif sugary_drinks_per_per_day == 1:\n",
        "        cavity = min(1.0, cavity * 1.05)\n",
        "\n",
        "    # scale to percentage\n",
        "    risks = {\"cavity\": round(cavity, 3), \"enamel\": round(enamel, 3), \"gum\": round(gum, 3)}\n",
        "    # build explanation lines\n",
        "    explanation = []\n",
        "    explanation.append(f\"Detected items: {', '.join(detected_items)}\")\n",
        "    explanation.append(f\"Total sugar (approx): {int(total_sugar)} g · Total calcium (approx): {int(total_calcium)} mg\")\n",
        "    if acid_present:\n",
        "        explanation.append(\"Acidic item present — enamel erosion risk increases.\")\n",
        "    if refined_frac > 0.3:\n",
        "        explanation.append(\"Refined/starchy foods present — cavity risk increases.\")\n",
        "    if sticky_frac > 0:\n",
        "        explanation.append(\"Some sticky/sugary treats detected — they cling to teeth.\")\n",
        "    # lifestyle part\n",
        "    if brushes_per_day >= 2:\n",
        "        explanation.append(\"Brushing twice daily — protective for cavity risk.\")\n",
        "    elif brushes_per_day == 1:\n",
        "        explanation.append(\"Brushing once daily — moderate protection.\")\n",
        "    else:\n",
        "        explanation.append(\"No brushing reported — risk increases.\")\n",
        "    if smokes:\n",
        "        explanation.append(\"Smoking — increases gum disease risk.\")\n",
        "    if sugary_drinks_per_day >= 1:\n",
        "        explanation.append(f\"Sugary drinks frequency reported: {sugary_drinks_per_day}/day — consider reducing.\")\n",
        "    explanation_str = \"\\n\".join(explanation)\n",
        "\n",
        "    # return both numeric risks and human explanation + item details\n",
        "    return risks, explanation_str, details\n",
        "\n",
        "# -------------------------\n",
        "# 6) Logging function (save to CSV)\n",
        "# -------------------------\n",
        "LOG_PATH = \"/content/oral_advisor_logs.csv\"\n",
        "def append_log(user_id, items, mode, risks, explanation):\n",
        "    # create file with header if not exist\n",
        "    header = [\"timestamp\",\"user_id\",\"mode\",\"items\",\"cavity\",\"enamel\",\"gum\",\"explanation\"]\n",
        "    exists = os.path.exists(LOG_PATH)\n",
        "    with open(LOG_PATH, \"a\", newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        if not exists:\n",
        "            writer.writerow(header)\n",
        "        writer.writerow([time.strftime(\"%Y-%m-%d %H:%M:%S\"), user_id, mode, \";\".join(items),\n",
        "                         risks[\"cavity\"], risks[\"enamel\"], risks[\"gum\"], explanation.replace(\"\\n\",\" | \")])\n",
        "\n",
        "def read_recent_logs(n=10):\n",
        "    if not os.path.exists(LOG_PATH):\n",
        "        return pd.DataFrame(columns=[\"timestamp\",\"user_id\",\"mode\",\"items\",\"cavity\",\"enamel\",\"gum\",\"explanation\"])\n",
        "    df = pd.read_csv(LOG_PATH)\n",
        "    return df.tail(n).iloc[::-1]\n",
        "\n",
        "# -------------------------\n",
        "# 7) Gradio interface functions\n",
        "# -------------------------\n",
        "def predict_from_photo(pil_img, meals_per_day, brushes_per_day, smokes_bool, sugary_drinks_per_day, user_id=\"anon\"):\n",
        "    if pil_img is None:\n",
        "        return \"No image provided.\", \"\", None\n",
        "    label, scores = classify_image_by_prototype(pil_img)\n",
        "    if label is None:\n",
        "        return \"No reference prototypes available. Add reference images to /content/reference.\", \"\", None\n",
        "    # map to canonical item names (could be list later)\n",
        "    detected_items = [label]\n",
        "    risks, explanation, details = compute_risk_and_explain(detected_items,\n",
        "                                                          meals_per_day=meals_per_day,\n",
        "                                                          brushes_per_day=brushes_per_day,\n",
        "                                                          smokes=smokes_bool,\n",
        "                                                          sugary_drinks_per_day=sugary_drinks_per_day)\n",
        "    # build human readable output\n",
        "    out_text = (f\"Detected: {label}\\n\\n\"\n",
        "               f\"Cavity Risk: {int(risks['cavity']*100)}%\\n\"\n",
        "               f\"Enamel Erosion Risk: {int(risks['enamel']*100)}%\\n\"\n",
        "               f\"Gum Disease Risk: {int(risks['gum']*100)}%\")\n",
        "    # explanations\n",
        "    explanation_full = explanation + \"\\n\\nContributors (item details):\\n\" + \"\\n\".join([f\"{d['item']}: sugar {d['sugar_g']}g, calcium {d['calcium_mg']}mg, acidic {d['acidic']}\" for d in details])\n",
        "    # log\n",
        "    append_log(user_id, detected_items, \"photo\", risks, explanation_full)\n",
        "    return out_text, explanation_full, label\n",
        "\n",
        "def predict_from_text_ui(food_text, meals_per_day, brushes_per_day, smokes_bool, sugary_drinks_per_day, user_id=\"anon\"):\n",
        "    items = [f.strip() for f in food_text.split(\",\") if f.strip()]\n",
        "    if len(items) == 0:\n",
        "        return \"Please type one or more food items (comma separated).\", \"\", None\n",
        "    risks, explanation, details = compute_risk_and_explain(items,\n",
        "                                                          meals_per_day=meals_per_day,\n",
        "                                                          brushes_per_day=brushes_per_day,\n",
        "                                                          smokes=smokes_bool,\n",
        "                                                          sugary_drinks_per_day=sugary_drinks_per_day)\n",
        "    out_text = (f\"Items: {', '.join(items)}\\n\\n\"\n",
        "               f\"Cavity Risk: {int(risks['cavity']*100)}%\\n\"\n",
        "               f\"Enamel Erosion Risk: {int(risks['enamel']*100)}%\\n\"\n",
        "               f\"Gum Disease Risk: {int(risks['gum']*100)}%\")\n",
        "    explanation_full = explanation + \"\\n\\nContributors (item details):\\n\" + \"\\n\".join([f\"{d['item']}: sugar {d['sugar_g']}g, calcium {d['calcium_mg']}mg, acidic {d['acidic']}\" for d in details])\n",
        "    append_log(user_id, items, \"text\", risks, explanation_full)\n",
        "    return out_text, explanation_full, \", \".join(items)\n",
        "\n",
        "def get_history():\n",
        "    df = read_recent_logs(20)\n",
        "    # show as string for Gradio\n",
        "    if df.empty:\n",
        "        return \"No logs yet.\"\n",
        "    return df.to_csv(index=False)\n",
        "\n",
        "# -------------------------\n",
        "# 8) Build Gradio UI (tabs)\n",
        "# -------------------------\n",
        "title = \"🦷 Oral-Health Dietary Advisor — Advanced Prototype\"\n",
        "description = \"Made by Kashish — Upload a food photo or type foods, add a few lifestyle answers, and get explainable oral health risk scores.\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(f\"# {title}\\n\\n{description}\")\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"Photo (fast, few-shot)\"):\n",
        "            with gr.Row():\n",
        "                img_in = gr.Image(type=\"pil\", label=\"Upload food photo\")\n",
        "                with gr.Column():\n",
        "                    meals_slider_p = gr.Slider(1, 8, value=3, step=1, label=\"Meals/snacks per day\")\n",
        "                    brushes_p = gr.Radio(choices=[\"0\",\"1\",\"2+\"], value=\"1\", label=\"Brushing per day\")\n",
        "                    smokes_p = gr.Checkbox(label=\"Do you smoke?\", value=False)\n",
        "                    sugarydrinks_p = gr.Slider(0,5, value=0, step=1, label=\"Sugary drinks per day\")\n",
        "                    user_id_p = gr.Textbox(label=\"Your name or id (optional)\", placeholder=\"e.g. Kashish\")\n",
        "                    btn_photo = gr.Button(\"Analyze Photo\")\n",
        "            out_photo_text = gr.Textbox(label=\"Risk Summary\", interactive=False)\n",
        "            out_photo_explain = gr.Textbox(label=\"Explanation & Contributors\", interactive=False)\n",
        "            out_label = gr.Textbox(label=\"Detected label (internal)\", interactive=False)\n",
        "            btn_photo.click(fn=lambda b,br,s,sd,m,u: predict_from_photo(b, m, int(br.replace(\"+\",\"\")) if isinstance(br,str) else int(br), s, sd, u),\n",
        "                            inputs=[img_in, meals_slider_p, brushes_p, smokes_p, sugarydrinks_p, user_id_p],\n",
        "                            outputs=[out_photo_text, out_photo_explain, out_label])\n",
        "\n",
        "        with gr.TabItem(\"Text (manual)\"):\n",
        "            with gr.Row():\n",
        "                text_in = gr.Textbox(lines=2, placeholder=\"e.g. cola, cheese, bread\")\n",
        "                with gr.Column():\n",
        "                    meals_slider_t = gr.Slider(1,8, value=3, step=1, label=\"Meals/snacks per day\")\n",
        "                    brushes_t = gr.Radio(choices=[\"0\",\"1\",\"2+\"], value=\"1\", label=\"Brushing per day\")\n",
        "                    smokes_t = gr.Checkbox(label=\"Do you smoke?\", value=False)\n",
        "                    sugarydrinks_t = gr.Slider(0,5, value=0, step=1, label=\"Sugary drinks per day\")\n",
        "                    user_id_t = gr.Textbox(label=\"Your name or id (optional)\", placeholder=\"e.g. Kashish\")\n",
        "                    btn_text = gr.Button(\"Analyze Text\")\n",
        "            out_text = gr.Textbox(label=\"Risk Summary\", interactive=False)\n",
        "            out_explain = gr.Textbox(label=\"Explanation & Contributors\", interactive=False)\n",
        "            out_items = gr.Textbox(label=\"Parsed items\", interactive=False)\n",
        "            btn_text.click(fn=lambda txt,m,br,s,sd,u: predict_from_text_ui(txt, m, int(br.replace(\"+\",\"\")) if isinstance(br,str) else int(br), s, sd, u),\n",
        "                           inputs=[text_in, meals_slider_t, brushes_t, smokes_t, sugarydrinks_t, user_id_t],\n",
        "                           outputs=[out_text, out_explain, out_items])\n",
        "\n",
        "        with gr.TabItem(\"History / Logs\"):\n",
        "            gr.Markdown(\"Recent analysis logs (CSV). You can download or inspect.\")\n",
        "            history_box = gr.Textbox(label=\"Recent logs (CSV)\", interactive=False)\n",
        "            btn_history = gr.Button(\"Load history\")\n",
        "            btn_history.click(fn=lambda: get_history(), inputs=[], outputs=[history_box])\n",
        "            gr.Markdown(\"Log file saved at `/content/oral_advisor_logs.csv` (download from Files panel in Colab).\")\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"**Disclaimer:** This is a research/demo tool (not a medical diagnosis). Consult a dentist for clinical advice. Your life matters, we have only one life to live, please take care of your health** \")\n",
        "    gr.Markdown(\"**Credits:** Made by Kashish\")\n",
        "\n",
        "# Launch (share=True gives a temporary public link from Colab)\n",
        "\n",
        "demo.launch(share=True)\n",
        "\n",
        "# Step 1: Mount Google Drive and Create Folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "folder_path = \"/content/drive/MyDrive/my_model_project\"\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "os.chdir(folder_path)\n",
        "!pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6V232Q697BB",
        "outputId": "e7c3b093-fb58-4038-e8a5-a703bc5cdc48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb3WJ5JjozqYveCNfrva1t",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}